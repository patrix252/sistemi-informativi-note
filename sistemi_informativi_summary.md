# Sommario Sistemi Informativi

### Capitolo 0
- **ICT e società della conoscenza**
- **ICT: trends, convergenza e conseguenze**
- **La digitalizzazione dell'informazione: caratteristiche**
- **ICT e comunicazione: aspetti tecnologici**
- **Nuove leggi della società della conoscenza**
    + `Moore`
    + `Sarnoff`: valore rete di broadcasting = utenti
    + `MetCalfe`: valore sistema di comunicazione = quadrato persone collegate
    + `Reed`: utilità reti di reti = esponenziale dimensione della rete
- **Hype Cycle di Gartner**
    + `Scintilla Tecnologica`: proof-of-concept, interesse dei media
    + `Picco di aspettative gonfiate`: pubblicità anticipata, storie di successo
    + `Ventre della disillusione`: produttori falliscono, miglioramento prodotto
    + `Risalita dell'illuminazione`: esempi aiutano a comprendere
    + `Altopiano della Produttività`: mercato mainstream decolla

### Concetti generali sull'informatica aziendale
- **Informatica, Informatica aziendale e Sistemi informativi aziendali**
    + `Informatica`: 
        * informazione + automatica
        * la scienza che studia i principi di rappresentazione ed elaborazione elettornica dell'informazione
    + `Sistema informativo`: l'insieme delle procedure e delle infrastrutture che definiscono e supportano il fluire delle informazioni all'interno di una struttura organizzativa
    + `Informatica aziendale`: disciplina che studia l'applicazione dell'informatica alle aziende e l'influenza dell'informatica sulle diverse categorie di elementi costituenti il sistema aziendale.
    + `Sistemi informativi aziendali`: hanno come obiettivo finale la distribuzione di informazioni alle persone che operano all'interno dell'azienda nel momento in cui l'informazione è necessaria.
- **L'impatto dell'informatica nelle aziende**: `BRP`
    + `Ridurre costi`
    + `Migliorare processi`
    + `Aumentare qualità dei dati`
- **L'impatto macroeconomico dell'IT, la sua evoluzione storica e i cambiamenti organizzativi generati**
    + `1,2% PIL`
    + `Mainframe` `Minicomputer` `PC`
    + Cambiamenti
        * Riduzione dei ruoli ipiegatizi
        * Riqualificazione dei ruoli
        * Riduzione dei ruoli di supporto
        * Revisione dei processi di front office
        * Revisione del modello organizzativo

### Struttura dell'azienda e del suo sistema informativo
- **Esigenza informatva**: `supportare chi fa funzionare l'azienda`
    + Livelli Operativi hanno bisogno di informazione dettagliata e attuale
    + Livelli Decisionali hanno bisogno di informazioni sintetiche
- **Schema di Anthony**
    + `Direzionale strategico`: identifica gli obiettivi primari
    + `Direzionale tattico`: analisi economica, previsioni
    + `Operativo`: attuazione dei piani
- Profili informativi
    + `Livello direzionale strategico`: informazioni sintetiche, diversificate, poco strutturare
    + `Livello direzionale tattico`: definizione e verifica di obiettivi, 
    + `Livello operativo`: registrazione eventi aziendali
- **Scomposizione del sistema informativo: sistemi operazioni e sistemi informazionali**
    + Operazionali: supporto alle attività
        * costituiscono l'infrastruttura informatica su cui si appoggia l'attività esecutiva
        * Funzioni: `automazione procedure` `supporto attività aziendali` `raccolta dati` `guida per l'operatore`
        * Componenti: `procedure` `base di dati`
    + Informazionali: supporto alle decisioni
        * processi decisionali non sono standardizzabili né riconducibili a procedure automatizzate
        * Funzioni: `informazioni sui risultati` `strumenti confronto` `facilitare processo decisionale`
        * Componenti: `data warehouse` `strumenti analisi` `procedure di alimentazione`

### Scelte organizzative
- **Costruzione del sistema informativo**
    + `Make`: costruzione interna
        * `costi` `obslescienza` `know-how interno` `ad hoc`
    + `Buy`: acquisto
        * `dipendenza` `flessiblità` `know-how uscita parziale` `propietà del sw` `mediazione modelli organizzativi`
    + `Outsource`: delegare gestione e organizzazione
        * `costi alti` `smobilizzazione investimenti` `dipendenza fornitore` `know-how uscita` `mediazione modelli organizzativi`
- **Posizionamento del sistema informativo**
    + `livello 1`: `poche persone diverse competenze` `struttura orrizontale`
    + `livello 2`: `responsabile EDP` `assistenza tecnico-sistemista` `assistenza applicativa` `sviluppo di nuove applicazioni`
    + `livello 3`: `propria Direzione` `EDP` `Responsabile nuove tecnologie`
    + `livello 4`: `direzione sistemi informativi`
- **Interrompibilità del servizio informatico**
    + `problemi HW`: `mortalità infantile`  `tempo di ripristino`
        * `rindondaza` `sistemi faut tolerant` `MTBF` `backup`
    + `problemi SW`: `ingegneria del sw` `struttura di supporto` `turn-around`
    + `azioni dolose`: `personale interno` `autenticazione` `autorizzazione`

### Sistemi operazionali
- **Finalità dei sistemi operazionali**
    + `registrazione transazioni`: operazioni elementari che rappresentano eventi `semplici` `complesse`
    + `pianificazione e controllo delle operazioni`: `monitoraggio` `efficenza aziendale` `punti critici`
    + `acquisizione e organizzazione della conoscenza`: archiviazione conoscenza aziendale `centralizzato` `strutturate` `correlate`
    + `elaborazione delle situazioni aziendali`: `indicatori di stato`
- **Potenzialità informatica (intensità e attrativa)**
    + Intensità informativa: alta complessità = alta intensità informativa
        * `Dimensione` `Area geografica su cui si estende sul mercato` `Appartenenza a un gruppo` `Livello di diversificazione prodotti, mercati e tecnologie`
        * `del prodotto`
        * `del processo`
        * `Schema Porter-Millar`
    + Attrattiva informatica
        * `Proceduralità` `Complessità` `Ripetitività` `Volume`
- **Catena del valore di Porter**
    + rappresentazione della struttura aziendale e per la segmentazione di bisogni informativi aziendali.
    + esaminare `attività aziendali` e rilevare aree di vantaggio competitivo attuale e potenziale
    + `Attività primarie` (market driven): proprie del core business dell'azienda
        * `logistica in entrata` `attività operative` `logistica in uscita` `marketing e vendite` `servizi postvendita`
    + `Attività secondarie` (di supporto): processi a sostegno delle primarie
        * `approvigionamenti` `gestione risorse umane` `sviluppo delle tecnologie` `infrastrutture`
- **Portafoglio istituzionale e operativo**
    + L'insieme delle applicazioni dei sistemi informativi operazionali dell'azienda può essere ripartito sulla base dello schema di Porter
    + `Portafoglio istituzionale`: `attività secondarie` `forte attrattiva informatica` `soluzioni standardizzate`
        * `contabilità` `finanziaria` `previsioni e controllo` `personale`
    + `Portafoglio operativo`: `attività primarie` `specializzazione` `dipende da attrattiva informatica`
        * `logica in entrata` `attività operative` `logistica in uscita` `marketing e vendite` `servizi postvendita`

### Il sistema ERP e le sue scomposizioni per sistemi
- `isole informatiche`: `anni 90` `autonome` `rigide` `specializzate` `eterogeneità dei sistemi` `autonomia dei sottosistemi`
- `ERP`: composti da sottosistemi nativamente integrati sviluppati da un'unica sw house, condividono `dati comune` e le procedure sono progettate per interagire e cooperare. `configuragili` `svincolati dell'organizzazione dell'azienda` `moduli indipendenti` `soluzioni standardizzate`
    + Sistemi di base: `amministrazione` `logistica` `vendite` `acquisti` `produzione`

### Sistemi informazionali
- **Presupposti per l'analisi**
    + `Sistemi di business intelligence`: `DDS`
        * supporta la dirigenza aziendale nel prendere decisioni `operative` `tattiche` e `strategiche` in modo efficace e veloce mediante particolari tipologie di elaborazione dette `analitiche` che usano in maniera integrata i dati dell'organizzazione combinati con eventuali dati esterni
    + Tipi di dati aziendali:
        * dati critici: `vitali per il successo` `gestire` `proteggere` `CIO`
        * dati ROT: `minimi` `eliminati periodicamente`
        * dati oscuri: `valore non identificato` `dati critici` `dati illegali`
    + Obiettivi:
        * `sfuttare patrimonio dati operazionali` `estrazoine informazioni utili` `strumenti per trasformare dati grezzi in informazione` `profilatura` `gestione` `miglioramento`
- **Sistemi OLTP e OLAP**
    + `OLTP`: ambiente che facilita la raccolta e l'elaborazione transazionale dei dati
        * `operazioni predefinite` `brevi` `semplici` `dati di dettaglio` `aggiornati` `ACID`
        * `impiegato` `supporto alle operazioni` `uso ripetitivo` `read-write` `migliaia utenti`
    + `OLAP`: ambiente che facilita l'analisi dei dati
        * `dati operazionali` `fonti esterne` `aggiornamento append` `reporting`
        * `dirigente` `supporto alle decisioni` `uso casuale` `read` `centinaia uteti`
    + Caratteristiche sistemi informazionali
        * Finalità: `descrivere passato` `identificare problemi e cause` `suggerire cambiamenti` `scenari futuri`
        * Struttura: `dati articolati intorno ad entità`
        * Utenza: `decisori` `manager`
    + ER in RDBMS non è adatto
        * Soluzioni: `BLOBs` `OODBMS` `Column-oriented DB` `NOSQL` `Machine Learning` `Data Mining`
- **RDMB, mondo analitico e performance**
    + `TCP`: organismo internazionale che diegna benchmark standard e ne omologa i risultati. Ritenuti i più importanti e significativi per la valutazione delle prestazioni dei sistemi che ospitano DBMS
    + Limitazioni DBMS:`gestione inefficiente delle relazioni multi-dimensionali` `problema delle normalizzazioni` `operazioni analitiche molto limitate` `consolidamento dei dati poco efficiente` `l'uso di join multiple causa perfomance pessime`
    + DB denormalizzati: `calo di performance` `aumentano latenze`
    + DB normalizzati: `+ integrità dati` `- data legibility` `troppe relazioni` `schema complesso` `percorsi tra tabelle non diretti` `naming conventions criptiche`
    + Parallel Query Processing: `solo certe query` `hw sw costoso`
    + Requisiti ideali: `chiarezza schema DW` `dati leggibili` `puliti` `navigabili` `query semplificate`
- **Il modello multidimensionale e le operazioni principali**
    + Struttura multidimensionale: struttura dati adatta all'analisi su cui si basano i sistemi informazionali. 
        * `intuitiva` `facilmente interpretabile` (`ricerche` `aggregazione` `disaggregatzione`) `efficienti`
        * analisi di modellazione su temi descritti da soggetti e da relazioni quantificabili tra soggetti
        * lo stesso evento può essere analizzato in relazione a diversi soggetti
        * la misura di ogni evento è descritta da un insieme di coordinate ognuna delle quali rappresenta un soggetto di interesse per le analisi da condurre su quell'evento
        * rappresentato con l'ipercubo (matrice multidimensionale)
            - `Fatto elementare`: l'elemento otenuto specificando un valore per ogni possibile coordinata
            - `Misure`: valori numerici che quantificano il fatto elementare
            - `Dimensioni`: coordinate di ciascun elemento che costituiscono l'analisi dei fatti
        * esempio:
            - Fatto: vendita prodotto
            - Misure: quantità e importo di vendita
            - Dimensioni: cliente che ha acquistato, articolo venduto, data
        * soluzioni esempio
            - quanti prodotti venduti di un certo tipo in un certo periodo?
            - quali sono i clienti con maggior fatturato?
            - quali articoli portano maggior fatturato?
            - quali sono principali acquirenti di un certo articolo?
    + Operazioni sui dati:
        * `Drill down`: `disaggrega` dati
            - dettaglia dati aggiungendo una dimensione di analisi
        * `Roll up`: `aggrega` dati
            - sintetizza dati eliminando una dimensione di analisi
        * `Slice & Dice`: seleziona e proietta
            - Slice: fissa il valore di una dimensione base
            - Dice: filtra i fatti 
        * `Pivot`: riorienta il cubo
            - inverte la realzione tra le dimensioni
- **Caratteristiche e modelli logici OLAP**
    + `ROLAP`: struttura multidimensionale su `database relazionale`
        * `sql standard`
        * Vantaggi: `minimo spazio` `conoscenza strumenti relazionali`
        * Svantaggi: `query poco efficienti` `+ velocità = + complessità`
    + `MOLAP`: struttura multidimensionale su `vettori ad accesso posizionale`
        * `una cella x combinazione di dimensioni` `accesso diretto` `strumenti di query proprietari`
        * Vantaggi: `efficienza query complesse` `aderenza modello concettuale`
        * Svantaggi: `occupazione spazio` `mancanza standard` 
    + `HOLAP`: combina vantaggi MOLAP e ROLAP
        * Data warehouse su db relazionale: `semplicità` `scalabilità`
        * Data mart su base multidimensionale: `interrogazioni efficienti` `dimensioni contenute`
- **Gli schemi multidimensionali: caratteristiche e tipi**
    + Caratteristiche
        * `Fatto`: evento che accade nell'ambito dell'attività e che si ha iteresse a misurare. es. vedite, spedizioni
            - identificazione tramite l'ennupla di coordinate `(dimensione1, ..., dimensioneN)`
        * `Misura`: caratteristica numerica del fatto, ogni fatto può avere più misure. `memorizzate su db` `calcolate` `implicite (presenza/assenza)`
            - identificazione tramite l'ennupla di coordinate `(dimensione1, ..., dimensioneN).Misura`
        * `Aggregabilità`: possibilità di usare l'operatore di aggregazione su una misura (tutte dimensioni) o su una specifica coppia (misura, dimensione)
        * `Additività`: possibilità di usare l'operatore di aggregazione somma su una misura (tutte dimensioni) o su una specifica coppia (misura, dimensione)
        * `Gerarchie`: insieme di attributi dimensionali collegati gerarchicamente ad una dimensione
    + Tipi
        * `Schema a stella`: una tabella dei fatti che referenzia un numero (da due in su) di tabelle di dimensioni
            - `semplice` `data mart` `riduzione join` `manutenzione ridotta` `collegamenti = chiavi esterne`
            - sconsigliato per un elevato numero di dimensioni
        * `Schema a fiocco di neve`: schema a stella con ramificazioni normalizzate sulle tabelle di dimensioni (anche più livelli)
            - `data warehouse` `estensione schema a stella` `normalizzazione db` `azzeramento rindondanza` `aggiornamento semplificato` `minore spazio` `accesso + veloce` `query + complesse` `creazione viste`
        * `Schema a costellazione`: tabelle dimensioni condivise da più tabelle dei fatti
            - `complesso`
            - approccio da seguire quando più fatti coinvolgono gli stessi elementi
    + Il banchmarking delle prestazione è essenziale per determinare quale sia il design migliore

### Data Warehouse e Data Mart
- **Data Warehouse e Data Mart**
    + `Data Warehouse`: Insieme di strutture dati e dei tool necessari per ottenere, a partire dai dati operazionali utilizzati e creati dal sistema informativo aziendale, informazioni che aiutino i manager nella valutazione tecnico-economica dell'andamento aziendale
        * `processo` `dati operazionali` `dati esterni` `accessibilità` `integrazione` `fressiblità` `sintesi` `rapresentzione multidimensionale` `correttezza` `compatezza` `lettura giorno` `aggiornamento notte`
        * Dati: `subject oriented` `aziendali e non dipartamentali` `aggregati` `asse temporale`
    + `Data Mart`: sottoinsieme del data warehouse contente l'insieme di informazioni rilevanti per un particolare problema
        * `contestuale` `limitato` `estensione temporale ridotta` `veloce e semplice` `costo inferiore` `risposte veloci` `limitato all'utente`
- **Architeture e modelli di DW**
    + Caratteristiche: `separazione` `scalabilità` `estendibilità` `sicurezza` `amministrabilità`
    + Diverse basi dati: `sorgenti` `staging area (opzionale)` `data warehouse` `data mart`
    + Flusso dati: `livello sogente` > `livello dell'alimentazione` > `livello DW` > `livello analisi`
    + Ciclo di vita (iterativo)
        * costruzione primo (fatto più significativo)
        * integrazione progressiva altri fatti
        * rilascio data mart
    + Architetture
        * 1 livello: `OLTP + OLAP`
        * 2 livello: `sorgenti` `data warehouse` `data mart`
        * 3 livello: `sorgenti` `staging area` `data warehouse` `data mart`
    + ETL
        * Extraction: `statica` `incrementale`
        * Transformation: `riconciliazione` `duplicati` `integrità` `coverstione tipi`
        * (Cleaning): `rilevazione errori` `correzione`
        * Loading: `batch to marts` `indicizzazione` `informazioni temporali` `generazione dati aggregati`
        * (Servizi di controllo): `metadati` `statistiche` `controllo qualità` `trattamento errori`
    + Modelli di DW
        * Central Data Warehouse (Enterprise Data Warehouse): enorme dw con dati da diversi database operativi e molti utenti
        * Distributed System: DW è distribuito su piattaforme multiple
        * Data Warehouse + Data Marts: dati estratti da DW centrale e caricati su sistemi più piccoli DM
        * Single Warehouse or Data Mart: singola fonte di dati operazionali orientati a servire pochi utenti (di dipartimento)
- **Vantaggi e svantaggi di un DW**
    + Vantaggi: `semplicità` `migliore qualità dei dati` `accesso rapido` `separazione ambiente operativo dall'ambiente DSS` `vantaggio competitivo` `costo operativo` `cgestion del flusso informativo` `bechmarking realistico` `sicurezza`
    + Svantaggi: `complessità nello sviluppo` `lunghi tempi di creazione` `dispendioso` `end-user traning` `complessità nell sfruttare SMP/MPP di DW` `difficoltà nel creare un ambiente DBMS distribuito` `time-lag tra DW e operazionale`

## Knowledge discovery, architettura e processi di data mining
- **Knowledge discovery, architettura e processi di data mining**
    + Knowledge discevery: processo di estrazione di pattern dai dati
        * pattern: `validi` `sconosciuti` `utli` `comprensibili`
    + OLAP -> `OLAM`: `non completamente automatico` 
    + Architettura dei sistemi di Data Mining
        * `Data Warehouse` `Knowledge Base` `Data Mining Engine` `Pattern Evaluation` `Sistema di presentazione`
    + Processo di mining: interrogazioni iterate su DW che portano progressivamente alla comprensione del fenomeno
        * `Comprensine del dominio` `Preparazione dati` `Scoperta pattern` `Valutazione pattern` `Utilizzo`
    + Parametri:
        * Porzione di dati da analizzare
        * Funzione di DM da usare in base all'obiettivo
            - `descrittive` `classificatorie` `predittive` `outliner` `eccezzioni` `livelli di approssimazione` `numero iterazioni`
        * Misure di interesse: `pattern` `novità` `semplicità` `certezza` `utilità`
        * Base di conoscenza: descrivere al sistema ciò che è noto all'utente
            - `regole` `parametri` `soglie` `gerarchie`
        * Visualizzazione dei pattern: `visualizzazione` `discovery` `navigazione`
- **Funzioni di data mining**
    + `mining descrittivo` `mining predittivo`
    + Generalizzazione, caratterizzazione e discriminazione
        * classificazione: gruppi caratterizzati da attributi comuni
        * caratterizzazione: descrizione delle particolarità della classe
        * discriminazione: marcamento delle differenze tra classi
    + Analisi associativa: identifica condizioni che si verificano contemporaneamente con elevata frequenza. Ne derivano regole di implicazione.
        * `confidenza`: misura certezza del pattern
        * `supporto`: misura frequenza della presenza del pattern
    + Classificazione e predizione: predire elementi futuri o stimare valori di elementi non noti
        * costruzione basata su esempi. si deriva un modello, valuta l'efficacia su diverso sottoinsieme
    + Classificazione: utente fornisce parametri per la creazione del modello. Ci sono diverse teniche: 
        * `funzioni matematiche` `regole associative` 
        * `alberi di decisione`: `build` `pruning`
        * `reti della verità bayesiane`: `rete di credenze` `prob condizionata`
        * `reti neurali`: quando un nodo riceve un input sopra una certa soglia di attivazione, emette a sua volta un segnale alle altre unità a cui è connesso
            - `nodi unità ingresso` `nodi unità uscita` `nodi unità nascoste`
            - apprendimento: `supervisionato` `non supervisionato` `per rinforzo`
            - proprietà: `capacità di apprendere da esempi` `capacità di generalizzare` `capacità di astrarre` `insensibilità al rumore` `decadimento graduale prestazioni`
    - Predizione: indentifica valori non noti il cui dominio è continuo.
        + funzioni di tendenza tramite interpolazione sui punti noti (regressione)
    - Clustering: ripartisce gli elementi in classi anonime sulla base delle affinità rilevate tramite l'osservazione dei dati. `agglomerati spontanei`
        + Caratteristiche:
            * massima similarità tra gli elementi appartenti ad una classe
            * minima similarità tra gli elementi appartenti a classi diverse
        + Tecniche: `metodi aggregativi (bottom-up)` `metodi divisivi (top-down)`
    - Ricerca outliner: identificazione degli elementi che si discostano maggiormente dagli altri
        + `risultato di clustering`
        + Tecniche: `statistici` `basati sulla distanza` `basati sulla deviazione`
- **Data Mining: aree applicative**
    + analisi finanziaria
        * analisi descrittive: `debiti` `incassi per mese` `regione` `settore`
        * classificazione clienti: `abitudini pagamento` `predizone pagamenti` `definizione politiche credito` `clienti critici`
        * analisi degli outliners: `frodi` `movimenti anomali`
    + marketing
        * analisi descrittive: `clienti` `prospect` `mercati potenziali` `aree di sviluppo`
        * clustering clienti: `azioni marketing puntuali`
        * classificazione clienti: `marketing mirato`
    + vendite
        * analisi descrittive: `clienti` `vendite` `reclami` `zone servite` `tempi di evasione`
        * analisi di associazione: `prodotti acquistati frequentemente`
        * analisi cluster: `schemi di acquisto`
        * analisi outliners: `condizioni anomale di vendita` `tendenze all'abbandono` `prodotti critici`
    + logistica
        * analisi associative: `materiali prelevati` `disposizione merce magazzino`
    + acquisti
        * caratterizzazione: `puntualità fornitori`
        * associazione: `confrontare prestazioni fornitori`
    + controllo qualità: 
        * analisi cluster: `classificazione prodotti diffetosi`  
        * analisi outliner: `elementi critici`
    + manutenzione:
        * analisi associative: `manutenzione preventiva`
    + sicurezza:
        * analisi outliner traffico rete: `intrusioni`
    + relazioni con il mercato:
        * analisi cluster dati accesso: `info + cercate`

## Linked Open Data
- **Data deluge**
    + Sommersi dai dai, ci possono aiutare a prendere decisioni migliori, hanno un ruolo sempre più centrale nelle nostre vite, guidano la data economy, costruire nuovi business.
        * `Amazon` `Google` `Società scientifiche` `Politica`
        * Come creare riuso dati?
        * Come identificare dati veramente importanti in questa moltitudine?
        * Come permettere alle applicazioni di integrare dati così diversi?
- **Links across distributed data**
    + Attuali meccanismi di riuso dei dati nel Web
        * `HTML`: testi o documenti piuttosto che dati, difficile estrarre dati
        * `Microformats`: dati strutturati che descrivono tipi di entità ristretti a piccoli insieme
        * `Web API`: dati strutturati attravero HTTP. codice ad hoc per accederci, non hanno un sistema per seguire i dati, scope locale (id_prodotto: 12345)
- **The global space of data**
    + Linked Data distribuiti richiedono meccanismi standard per specificare l'esistenza e il significato delle connessioni tra gli items descritti in questi dati.
    + RDF fornisce un modo flessibile per descrivere cose nel mondo, e come sono relazionati fra loro
        * `connette cose, non documenti` `descrive le connessioni`
        * `links espliciti` `seguire dati` `trovare altri dati`
    + Dati di diverse sorgenti creano un unico `Global Data Space`
    + L'adozione dei linked data crea `Web of Data` `Semantic Web`
- **Principles of Linked Data**
    + Linked Data: best practices per la pubblicazione e la relazione di dati strutturati sul web. `Tim Berners-Lee` `usare archittetura già esistente` `URI` `HTTP` `HTML`
        * Usare gli URIs come nome delle cose
        * Usare HTTP URIs, così che le persone possano cercare questi nomi
        * Quando qualcuno cerca un URI, fornire informazioni utili, usando standards come REF, SPARQL
        * Includere links di altri URIs, così che si possano trovare più cose
    + `Linked Data Browser` `Linked Data Search Engine`
- **Naming thing with URIs**
    + Per identificare entità e relazioni si usano gli URIs
        * semplice creare nomi univoci a livello globare in modo decetralizzato
        * descrivono il significato
- **Making URIs Deferenceable**
    + Tutti gli URI dovrebbero essere deferenzibili per recuperare la descrizione della risorsa
    + `content negotiation` `HTML > Umani` `RDF > Macchine`
    + Tecniche deferenziazione
        * 303 URIs (303 Redirect): `303 See Other`
            - `flessibili` `diversi target` `+ richieste HTTP` `grandi data set`
        * Hash URIs: `fragment identifier`
            - `- richieste HTTP` `- latenza` `informazioni inutili` `vocabolari` `embeddati HTML RDFa`
- **Providing Useful RDF Information**
    + Formati serializazzione: `RDF/XML` `RDFa` (`JSON-LD`)
    + i modelli RDF rappresentano informazioni rappresentate come nodi e archi etichettati di un grafo orientato, e sono disegnati per integrare reppresentazioni di informazioni originate da diverse sorgenti
    + Composizione tripletta
        * Soggetto: URI che identifica la risorsa
        * Predicato: URI indica il tipo di relazione (vocabolario)
        * Oggetto: letterale o URI
    + Tipi triplette
        * Triplette letterali: `oggetto letterale` `descrivono proprietà` `datatype URI`
        * RDF Links: `3 URIs` `descrivono relazioni`
            - RDF Links Interno: `stesso Linked Data Source`
            - RDF Links Esterno: `diverso Linked Data Source`
- **Linking to other things**
    + RDF Links
        * Relationship Link: `altri data source` `paolo->biblioteca`
        * Identity Link: `alias` `sistema sociale` `diverse opinioni` `tracciabilità` `decentralizzazione`
        * Vocabulary Link
- **5 stars model for open data**
    - `Tim Berners-Lee` sistema dove i publisher possono dare un premio ai loro data set in base ai seguenti criteri
    - 1 Stella: disponibile Web, Open
    - 2 Stelle: strutturati per una macchina `Excel`
    - 3 Stelle: formato Open `CSV`
    - 4 Stelle: standard aperti `W3C` per identificare i dati `RDF` `SPARQL`
    - 5 Stelle: links uscenti verso altri data set